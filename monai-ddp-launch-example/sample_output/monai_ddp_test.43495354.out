Primary node: c1009a-s11
Primary TCP port: 16755
Secondary nodes: 
Running "/mnt/unet_training_ddp_slurm_torchlaunch.py --dir ./testdata" on each node...
/home/hityangsir/red/MultiNode_MONAI_example/launch-ddp-launch-example
c1009a-s11.ufhpc
Fri Jul 29 17:11:59 EDT 2022
starting PID = 256705
[33mWARNING:[0m Bind mount '/home/hityangsir => /home/hityangsir' overlaps container CWD /home/hityangsir/red/MultiNode_MONAI_example/launch-ddp-launch-example, may not be available
[33mWARNING:[0m underlay of /etc/localtime required more than 50 (92) bind mounts
[33mWARNING:[0m underlay of /usr/bin/nvidia-smi required more than 50 (473) bind mounts
The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.
 Please read local_rank from `os.environ('LOCAL_RANK')` instead.
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : /mnt/unet_training_ddp_slurm_torchlaunch.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 4
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : c1009a-s11:16755
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /scratch/local/43495354/torchelastic_6xvvp3mn/none_anto872e
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python3
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/opt/conda/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=c1009a-s11
  master_port=16755
  group_rank=0
  group_world_size=1
  local_ranks=[0, 1, 2, 3]
  role_ranks=[0, 1, 2, 3]
  global_ranks=[0, 1, 2, 3]
  role_world_sizes=[4, 4, 4, 4]
  global_world_sizes=[4, 4, 4, 4]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /scratch/local/43495354/torchelastic_6xvvp3mn/none_anto872e/attempt_0/0/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /scratch/local/43495354/torchelastic_6xvvp3mn/none_anto872e/attempt_0/1/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /scratch/local/43495354/torchelastic_6xvvp3mn/none_anto872e/attempt_0/2/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /scratch/local/43495354/torchelastic_6xvvp3mn/none_anto872e/attempt_0/3/error.json
PID=[256798]: Initializing process group with: {'MASTER_ADDR': 'c1009a-s11', 'MASTER_PORT': '16755', 'RANK': '0', 'WORLD_SIZE': '4'}
PID=[256799]: Initializing process group with: {'MASTER_ADDR': 'c1009a-s11', 'MASTER_PORT': '16755', 'RANK': '1', 'WORLD_SIZE': '4'}
PID=[256800]: Initializing process group with: {'MASTER_ADDR': 'c1009a-s11', 'MASTER_PORT': '16755', 'RANK': '2', 'WORLD_SIZE': '4'}
PID=[256802]: Initializing process group with: {'MASTER_ADDR': 'c1009a-s11', 'MASTER_PORT': '16755', 'RANK': '3', 'WORLD_SIZE': '4'}
NCCL version 2.10.3+cuda11.4
[1] ---------- epoch 1/5
[2] ---------- epoch 1/5
[0] ---------- epoch 1/5[3] ---------- epoch 1/5

[2] 1/32, train_loss: 0.7556
[1] 1/32, train_loss: 0.6537
[3] 1/32, train_loss: 0.6654
[0] 1/32, train_loss: 0.6736
[2] 2/32, train_loss: 0.6503
[1] 2/32, train_loss: 0.5730
[3] 2/32, train_loss: 0.4942
[0] 2/32, train_loss: 0.5411
[2] 3/32, train_loss: 0.5254
[1] 3/32, train_loss: 0.4979
[3] 3/32, train_loss: 0.5180
[0] 3/32, train_loss: 0.4798
[2] 4/32, train_loss: 0.5223
[3] 4/32, train_loss: 0.4989
[0] 4/32, train_loss: 0.5136
[1] 4/32, train_loss: 0.5083
[1] 5/32, train_loss: 0.5354
[0] 5/32, train_loss: 0.4974
[3] 5/32, train_loss: 0.6301
[2] 5/32, train_loss: 0.4509
[2] 6/32, train_loss: 0.4306
[3] 6/32, train_loss: 0.4808
[0] 6/32, train_loss: 0.4471
[1] 6/32, train_loss: 0.4675
[2] 7/32, train_loss: 0.4637
[1] 7/32, train_loss: 0.4644
[3] 7/32, train_loss: 0.4434
[0] 7/32, train_loss: 0.4678
[2] 8/32, train_loss: 0.5560
[1] 8/32, train_loss: 0.4987
[3] 8/32, train_loss: 0.4510
[0] 8/32, train_loss: 0.4266
[1] epoch 1, average loss: 0.5249
[1] ---------- epoch 2/5
[0] epoch 1, average loss: 0.5059
[0] ---------- epoch 2/5
[2] epoch 1, average loss: 0.5444
[2] ---------- epoch 2/5
[3] epoch 1, average loss: 0.5227
[3] ---------- epoch 2/5
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[1] 1/32, train_loss: 0.4884
[0] 1/32, train_loss: 0.4674
[3] 1/32, train_loss: 0.5328
[2] 1/32, train_loss: 0.4706
[2] 2/32, train_loss: 0.4816
[1] 2/32, train_loss: 0.4638
[3] 2/32, train_loss: 0.4926
[0] 2/32, train_loss: 0.4261
[2] 3/32, train_loss: 0.4369
[1] 3/32, train_loss: 0.4019
[0] 3/32, train_loss: 0.4408
[3] 3/32, train_loss: 0.5259
[2] 4/32, train_loss: 0.5105
[1] 4/32, train_loss: 0.4472
[3] 4/32, train_loss: 0.4381
[0] 4/32, train_loss: 0.4237
[2] 5/32, train_loss: 0.4464
[1] 5/32, train_loss: 0.4615
[0] 5/32, train_loss: 0.4361
[3] 5/32, train_loss: 0.5959
[2] 6/32, train_loss: 0.4458[1] 6/32, train_loss: 0.4469

[3] 6/32, train_loss: 0.4082
[0] 6/32, train_loss: 0.4680
[2] 7/32, train_loss: 0.5374
[1] 7/32, train_loss: 0.4239
[3] 7/32, train_loss: 0.4264
[0] 7/32, train_loss: 0.4474
[2] 8/32, train_loss: 0.4843[1] 8/32, train_loss: 0.3725

[3] 8/32, train_loss: 0.3648
[0] 8/32, train_loss: 0.4722
[3] epoch 2, average loss: 0.4731
[3] ---------- epoch 3/5
[0] epoch 2, average loss: 0.4477
[0] ---------- epoch 3/5
[2] epoch 2, average loss: 0.4767
[2] ---------- epoch 3/5
[1] epoch 2, average loss: 0.4383
[1] ---------- epoch 3/5
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[1] 1/32, train_loss: 0.4276
[0] 1/32, train_loss: 0.4195
[3] 1/32, train_loss: 0.4803
[2] 1/32, train_loss: 0.4860
[2] 2/32, train_loss: 0.5111[3] 2/32, train_loss: 0.4315

[1] 2/32, train_loss: 0.3677
[0] 2/32, train_loss: 0.4435
[0] 3/32, train_loss: 0.4565
[3] 3/32, train_loss: 0.3658
[2] 3/32, train_loss: 0.4404
[1] 3/32, train_loss: 0.4805
[2] 4/32, train_loss: 0.4804[1] 4/32, train_loss: 0.4255

[3] 4/32, train_loss: 0.4108
[0] 4/32, train_loss: 0.4491
[1] 5/32, train_loss: 0.4926[3] 5/32, train_loss: 0.4148

[0] 5/32, train_loss: 0.4060
[2] 5/32, train_loss: 0.5034
[2] 6/32, train_loss: 0.3785[1] 6/32, train_loss: 0.3882

[3] 6/32, train_loss: 0.4257
[0] 6/32, train_loss: 0.4050
[1] 7/32, train_loss: 0.5487
[3] 7/32, train_loss: 0.4065
[0] 7/32, train_loss: 0.3815
[2] 7/32, train_loss: 0.3961
[2] 8/32, train_loss: 0.4279[1] 8/32, train_loss: 0.5330

[3] 8/32, train_loss: 0.4253
[0] 8/32, train_loss: 0.4188
[0] epoch 3, average loss: 0.4225
[0] ---------- epoch 4/5
[1] epoch 3, average loss: 0.4580
[1] ---------- epoch 4/5
[3] epoch 3, average loss: 0.4201
[3] ---------- epoch 4/5
[2] epoch 3, average loss: 0.4530
[2] ---------- epoch 4/5
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[1] 1/32, train_loss: 0.4047
[2] 1/32, train_loss: 0.5463
[0] 1/32, train_loss: 0.4394
[3] 1/32, train_loss: 0.3814
[2] 2/32, train_loss: 0.3516[1] 2/32, train_loss: 0.3936

[0] 2/32, train_loss: 0.5482
[3] 2/32, train_loss: 0.4445
[2] 3/32, train_loss: 0.3673[0] 3/32, train_loss: 0.4104[3] 3/32, train_loss: 0.5835


[1] 3/32, train_loss: 0.3891
[2] 4/32, train_loss: 0.4203
[0] 4/32, train_loss: 0.3442
[3] 4/32, train_loss: 0.4216
[1] 4/32, train_loss: 0.4172
[2] 5/32, train_loss: 0.4056[0] 5/32, train_loss: 0.4131

[1] 5/32, train_loss: 0.4409
[3] 5/32, train_loss: 0.3511
[2] 6/32, train_loss: 0.4097[1] 6/32, train_loss: 0.4566

[0] 6/32, train_loss: 0.4055
[3] 6/32, train_loss: 0.3599
[1] 7/32, train_loss: 0.4448
[2] 7/32, train_loss: 0.3378
[3] 7/32, train_loss: 0.4139
[0] 7/32, train_loss: 0.3703
[2] 8/32, train_loss: 0.4461[1] 8/32, train_loss: 0.3946

[3] 8/32, train_loss: 0.4322
[0] 8/32, train_loss: 0.4831
[2] epoch 4, average loss: 0.4106
[2] ---------- epoch 5/5
[1] epoch 4, average loss: 0.4177
[1] ---------- epoch 5/5
[3] epoch 4, average loss: 0.4235
[3] ---------- epoch 5/5
[0] epoch 4, average loss: 0.4268
[0] ---------- epoch 5/5
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[1] 1/32, train_loss: 0.5080
[2] 1/32, train_loss: 0.4001
[0] 1/32, train_loss: 0.4532
[3] 1/32, train_loss: 0.4012
[1] 2/32, train_loss: 0.3890[2] 2/32, train_loss: 0.3836

[3] 2/32, train_loss: 0.5538
[0] 2/32, train_loss: 0.3475
[2] 3/32, train_loss: 0.3818
[3] 3/32, train_loss: 0.3446
[1] 3/32, train_loss: 0.3406
[0] 3/32, train_loss: 0.4243
[2] 4/32, train_loss: 0.3683
[3] 4/32, train_loss: 0.3937
[0] 4/32, train_loss: 0.3878
[1] 4/32, train_loss: 0.4053
[2] 5/32, train_loss: 0.4024
[0] 5/32, train_loss: 0.3944
[3] 5/32, train_loss: 0.3784
[1] 5/32, train_loss: 0.4506
[1] 6/32, train_loss: 0.5036[2] 6/32, train_loss: 0.3585

[3] 6/32, train_loss: 0.3639
[0] 6/32, train_loss: 0.4027
[0] 7/32, train_loss: 0.3619[1] 7/32, train_loss: 0.3829

[3] 7/32, train_loss: 0.4002
[2] 7/32, train_loss: 0.4744
[1] 8/32, train_loss: 0.3904[2] 8/32, train_loss: 0.4532

[3] 8/32, train_loss: 0.3832
[0] 8/32, train_loss: 0.4193
[3] epoch 5, average loss: 0.4024
[3] train completed, epoch losses: [0.5227393917739391, 0.4730929210782051, 0.4200936406850815, 0.42352303862571716, 0.402379896491766]
[1] epoch 5, average loss: 0.4213
[1] train completed, epoch losses: [0.524864636361599, 0.43827639520168304, 0.45800019055604935, 0.4176894314587116, 0.42129063978791237]
[2] epoch 5, average loss: 0.4028
[2] train completed, epoch losses: [0.5443652085959911, 0.47669384628534317, 0.4529702365398407, 0.4106011427938938, 0.40277136862277985]
[0] epoch 5, average loss: 0.3989
[0] train completed, epoch losses: [0.5058908127248287, 0.44771696254611015, 0.4224846586585045, 0.4267706163227558, 0.3988884352147579]
INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.
INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish
/opt/conda/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:70: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.0003075599670410156 seconds
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 0, "group_rank": 0, "worker_id": "256798", "role": "default", "hostname": "c1009a-s11.ufhpc", "state": "SUCCEEDED", "total_run_time": 30, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python3\", \"local_rank\": [0], \"role_rank\": [0], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 1, "group_rank": 0, "worker_id": "256799", "role": "default", "hostname": "c1009a-s11.ufhpc", "state": "SUCCEEDED", "total_run_time": 30, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python3\", \"local_rank\": [1], \"role_rank\": [1], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 2, "group_rank": 0, "worker_id": "256800", "role": "default", "hostname": "c1009a-s11.ufhpc", "state": "SUCCEEDED", "total_run_time": 30, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python3\", \"local_rank\": [2], \"role_rank\": [2], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 3, "group_rank": 0, "worker_id": "256802", "role": "default", "hostname": "c1009a-s11.ufhpc", "state": "SUCCEEDED", "total_run_time": 30, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python3\", \"local_rank\": [3], \"role_rank\": [3], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "AGENT", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": null, "group_rank": 0, "worker_id": null, "role": "default", "hostname": "c1009a-s11.ufhpc", "state": "SUCCEEDED", "total_run_time": 30, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python3\"}", "agent_restarts": 0}}
