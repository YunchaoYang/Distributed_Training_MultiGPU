Primary node: 
Primary TCP port: 
Secondary nodes: 
Node IP: 172.16.204.41
/home/hityangsir/parallel/MultiGPU_Training_Examples/pytorch_launch_per_node/torchrun/tutorial/ddp-tutorial-series/slurm
c0900a-s11.ufhpc
Thu Sep 21 11:07:45 EDT 2023
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : multigpu_torchrun.py
  min_nodes        : 4
  max_nodes        : 4
  nproc_per_node   : 1
  run_id           : 27098
  rdzv_backend     : c10d
  rdzv_endpoint    : 172.16.204.41:29500
  rdzv_configs     : {'timeout': 900}
  max_restarts     : 0
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /scratch/local/10486071/torchelastic_t3uigljh/27098_jkaslcer
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : multigpu_torchrun.py
  min_nodes        : 4
  max_nodes        : 4
  nproc_per_node   : 1
  run_id           : 27098
  rdzv_backend     : c10d
  rdzv_endpoint    : 172.16.204.41:29500
  rdzv_configs     : {'timeout': 900}
  max_restarts     : 0
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : multigpu_torchrun.py
  min_nodes        : 4
  max_nodes        : 4
  nproc_per_node   : 1
  run_id           : 27098
  rdzv_backend     : c10d
  rdzv_endpoint    : 172.16.204.41:29500
  rdzv_configs     : {'timeout': 900}
  max_restarts     : 0
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : multigpu_torchrun.py
  min_nodes        : 4
  max_nodes        : 4
  nproc_per_node   : 1
  run_id           : 27098
  rdzv_backend     : c10d
  rdzv_endpoint    : 172.16.204.41:29500
  rdzv_configs     : {'timeout': 900}
  max_restarts     : 0
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /scratch/local/10486071/torchelastic_i1oy8sjg/27098_4qffd_ct
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /scratch/local/10486071/torchelastic_oofl6288/27098_stvpqh94
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /scratch/local/10486071/torchelastic_nqsgda9g/27098_ry6oizkx
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=c0900a-s11.ufhpc
  master_port=49283
  group_rank=0
  group_world_size=4
  local_ranks=[0]
  role_ranks=[0]
  global_ranks=[0]
  role_world_sizes=[4]
  global_world_sizes=[4]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /scratch/local/10486071/torchelastic_t3uigljh/27098_jkaslcer/attempt_0/0/error.json
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=c0900a-s11.ufhpc
  master_port=49283
  group_rank=1
  group_world_size=4
  local_ranks=[0]
  role_ranks=[1]
  global_ranks=[1]
  role_world_sizes=[4]
  global_world_sizes=[4]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=c0900a-s11.ufhpc
  master_port=49283
  group_rank=2
  group_world_size=4
  local_ranks=[0]
  role_ranks=[2]
  global_ranks=[2]
  role_world_sizes=[4]
  global_world_sizes=[4]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /scratch/local/10486071/torchelastic_nqsgda9g/27098_ry6oizkx/attempt_0/0/error.json
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=c0900a-s11.ufhpc
  master_port=49283
  group_rank=3
  group_world_size=4
  local_ranks=[0]
  role_ranks=[3]
  global_ranks=[3]
  role_world_sizes=[4]
  global_world_sizes=[4]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /scratch/local/10486071/torchelastic_i1oy8sjg/27098_4qffd_ct/attempt_0/0/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /scratch/local/10486071/torchelastic_oofl6288/27098_stvpqh94/attempt_0/0/error.json
Loading snapshot
Resuming training from snapshot at Epoch 40
Loading snapshot
Resuming training from snapshot at Epoch 40
Loading snapshot
Resuming training from snapshot at Epoch 40
Loading snapshot
Resuming training from snapshot at Epoch 40
NCCL version 2.10.3+cuda11.3
[RANK0: local GPU0] Epoch 40 | Batchsize: 32 | Steps: 16
[RANK1: local GPU0] Epoch 40 | Batchsize: 32 | Steps: 16
[RANK3: local GPU0] Epoch 40 | Batchsize: 32 | Steps: 16
[RANK2: local GPU0] Epoch 40 | Batchsize: 32 | Steps: 16
Epoch 40 | Training snapshot saved at snapshot.pt
[RANK0: local GPU0] Epoch 41 | Batchsize: 32 | Steps: 16
Epoch 40 | Training snapshot saved at snapshot.pt
[RANK3: local GPU0] Epoch 41 | Batchsize: 32 | Steps: 16
Epoch 40 | Training snapshot saved at snapshot.pt
[RANK2: local GPU0] Epoch 41 | Batchsize: 32 | Steps: 16
Epoch 40 | Training snapshot saved at snapshot.pt
[RANK1: local GPU0] Epoch 41 | Batchsize: 32 | Steps: 16
[RANK0: local GPU0] Epoch 42 | Batchsize: 32 | Steps: 16
[RANK3: local GPU0] Epoch 42 | Batchsize: 32 | Steps: 16
[RANK2: local GPU0] Epoch 42 | Batchsize: 32 | Steps: 16
[RANK1: local GPU0] Epoch 42 | Batchsize: 32 | Steps: 16
[RANK0: local GPU0] Epoch 43 | Batchsize: 32 | Steps: 16
[RANK2: local GPU0] Epoch 43 | Batchsize: 32 | Steps: 16
[RANK3: local GPU0] Epoch 43 | Batchsize: 32 | Steps: 16
[RANK1: local GPU0] Epoch 43 | Batchsize: 32 | Steps: 16
[RANK0: local GPU0] Epoch 44 | Batchsize: 32 | Steps: 16
[RANK3: local GPU0] Epoch 44 | Batchsize: 32 | Steps: 16
[RANK2: local GPU0] Epoch 44 | Batchsize: 32 | Steps: 16
[RANK1: local GPU0] Epoch 44 | Batchsize: 32 | Steps: 16
[RANK0: local GPU0] Epoch 45 | Batchsize: 32 | Steps: 16
[RANK3: local GPU0] Epoch 45 | Batchsize: 32 | Steps: 16
[RANK2: local GPU0] Epoch 45 | Batchsize: 32 | Steps: 16
[RANK1: local GPU0] Epoch 45 | Batchsize: 32 | Steps: 16
[RANK0: local GPU0] Epoch 46 | Batchsize: 32 | Steps: 16
[RANK3: local GPU0] Epoch 46 | Batchsize: 32 | Steps: 16
[RANK2: local GPU0] Epoch 46 | Batchsize: 32 | Steps: 16
[RANK1: local GPU0] Epoch 46 | Batchsize: 32 | Steps: 16
[RANK0: local GPU0] Epoch 47 | Batchsize: 32 | Steps: 16
[RANK3: local GPU0] Epoch 47 | Batchsize: 32 | Steps: 16
[RANK1: local GPU0] Epoch 47 | Batchsize: 32 | Steps: 16
[RANK2: local GPU0] Epoch 47 | Batchsize: 32 | Steps: 16
[RANK3: local GPU0] Epoch 48 | Batchsize: 32 | Steps: 16
[RANK0: local GPU0] Epoch 48 | Batchsize: 32 | Steps: 16
[RANK1: local GPU0] Epoch 48 | Batchsize: 32 | Steps: 16
[RANK2: local GPU0] Epoch 48 | Batchsize: 32 | Steps: 16
[RANK3: local GPU0] Epoch 49 | Batchsize: 32 | Steps: 16
[RANK0: local GPU0] Epoch 49 | Batchsize: 32 | Steps: 16
[RANK1: local GPU0] Epoch 49 | Batchsize: 32 | Steps: 16
[RANK2: local GPU0] Epoch 49 | Batchsize: 32 | Steps: 16
INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.
INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish
INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.
INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish
INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.
INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish
INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.
INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish
INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.0013086795806884766 seconds
INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.0014445781707763672 seconds
INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.00418853759765625 seconds
INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.0010013580322265625 seconds
